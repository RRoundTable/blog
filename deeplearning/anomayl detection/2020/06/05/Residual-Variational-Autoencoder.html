<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Residual Variational Autoencoder: Anomaly Detection에 활용하기 | RoundTable</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Residual Variational Autoencoder: Anomaly Detection에 활용하기" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Residual Variational Autoencoder: Anomaly Detection에 활용하기" />
<meta property="og:description" content="Residual Variational Autoencoder: Anomaly Detection에 활용하기" />
<link rel="canonical" href="https://fastpages.fast.ai/blog/deeplearning/anomayl%20detection/2020/06/05/Residual-Variational-Autoencoder.html" />
<meta property="og:url" content="https://fastpages.fast.ai/blog/deeplearning/anomayl%20detection/2020/06/05/Residual-Variational-Autoencoder.html" />
<meta property="og:site_name" content="RoundTable" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-05T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Residual Variational Autoencoder: Anomaly Detection에 활용하기","mainEntityOfPage":{"@type":"WebPage","@id":"https://fastpages.fast.ai/blog/deeplearning/anomayl%20detection/2020/06/05/Residual-Variational-Autoencoder.html"},"@type":"BlogPosting","url":"https://fastpages.fast.ai/blog/deeplearning/anomayl%20detection/2020/06/05/Residual-Variational-Autoencoder.html","headline":"Residual Variational Autoencoder: Anomaly Detection에 활용하기","dateModified":"2020-06-05T00:00:00-05:00","datePublished":"2020-06-05T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://fastpages.fast.ai/blog/feed.xml" title="RoundTable" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-57531313-5','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Residual Variational Autoencoder: Anomaly Detection에 활용하기 | RoundTable</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Residual Variational Autoencoder: Anomaly Detection에 활용하기" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Residual Variational Autoencoder: Anomaly Detection에 활용하기" />
<meta property="og:description" content="Residual Variational Autoencoder: Anomaly Detection에 활용하기" />
<link rel="canonical" href="https://fastpages.fast.ai/blog/deeplearning/anomayl%20detection/2020/06/05/Residual-Variational-Autoencoder.html" />
<meta property="og:url" content="https://fastpages.fast.ai/blog/deeplearning/anomayl%20detection/2020/06/05/Residual-Variational-Autoencoder.html" />
<meta property="og:site_name" content="RoundTable" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-05T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Residual Variational Autoencoder: Anomaly Detection에 활용하기","mainEntityOfPage":{"@type":"WebPage","@id":"https://fastpages.fast.ai/blog/deeplearning/anomayl%20detection/2020/06/05/Residual-Variational-Autoencoder.html"},"@type":"BlogPosting","url":"https://fastpages.fast.ai/blog/deeplearning/anomayl%20detection/2020/06/05/Residual-Variational-Autoencoder.html","headline":"Residual Variational Autoencoder: Anomaly Detection에 활용하기","dateModified":"2020-06-05T00:00:00-05:00","datePublished":"2020-06-05T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://fastpages.fast.ai/blog/feed.xml" title="RoundTable" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-57531313-5','auto');ga('require','displayfeatures');ga('send','pageview');</script>


    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
<script type="text/javascript">
require.config({
  paths: {
    jquery: 'https://code.jquery.com/jquery-3.5.0.min',
    plotly: 'https://cdn.plot.ly/plotly-latest.min'
  },

  shim: {
    plotly: {
      deps: ['jquery'],
      exports: 'plotly'
    }
  }
});
</script>

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">RoundTable</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Residual Variational Autoencoder: Anomaly Detection에 활용하기</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-06-05T00:00:00-05:00" itemprop="datePublished">
        Jun 5, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      8 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#deeplearning">deeplearning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#anomayl detection">anomayl detection</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#residual-variational-autoencoder-anomaly-detection에-활용하기">Residual Variational Autoencoder: Anomaly Detection에 활용하기</a>
<ul>
<li class="toc-entry toc-h2"><a href="#introduction">Introduction</a></li>
<li class="toc-entry toc-h2"><a href="#related-works">Related Works</a>
<ul>
<li class="toc-entry toc-h3"><a href="#residual-connection">Residual Connection</a></li>
<li class="toc-entry toc-h3"><a href="#gradient-explosion-in-deep-network">Gradient Explosion in deep network</a></li>
<li class="toc-entry toc-h3"><a href="#anomaly-detection-based-on-autoencoder">Anomaly detection based on Autoencoder</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#anomaly-detection-based-on-variational-autoencoder">Anomaly detection based on Variational Autoencoder</a></li>
<li class="toc-entry toc-h2"><a href="#motivation">Motivation</a></li>
<li class="toc-entry toc-h2"><a href="#method">Method</a>
<ul>
<li class="toc-entry toc-h3"><a href="#degradation-residual-connection">Degradation: Residual Connection</a></li>
<li class="toc-entry toc-h3"><a href="#gradient-explosion-gradient-clipping">Gradient Explosion: Gradient Clipping</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#experiments">Experiments</a>
<ul>
<li class="toc-entry toc-h3"><a href="#rae-vs-ae">RAE vs AE</a>
<ul>
<li class="toc-entry toc-h4"><a href="#train-loss">Train loss</a></li>
<li class="toc-entry toc-h4"><a href="#auroc">AUROC</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#rvae-vs-vae">RVAE vs VAE</a>
<ul>
<li class="toc-entry toc-h4"><a href="#auroc-1">AUROC</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#summary">Summary</a></li>
<li class="toc-entry toc-h2"><a href="#references">References</a></li>
</ul>
</li>
</ul><h1 id="residual-variational-autoencoder-anomaly-detection에-활용하기">
<a class="anchor" href="#residual-variational-autoencoder-anomaly-detection%EC%97%90-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0" aria-hidden="true"><span class="octicon octicon-link"></span></a>Residual Variational Autoencoder: Anomaly Detection에 활용하기</h1>

<h2 id="introduction">
<a class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h2>

<p>이번 포스팅은 마키나락스에서 내부적으로 개발한 Residual Variational Autoencoder에 대해서 작성하였습니다.</p>

<p>많은 딥러닝의 연구들은 비선형적인 레이어를 깊게 쌓으면서 좋은 성능을 보여줬습니다. 대표적인 예로, Resnet의 경우에 더 깊은 레이어를 효과적으로 쌓아 성능향상을 이루었습니다.</p>

<p>같은 맥락으로 Residual Variational Autoencoder은 레이어를 효과적으로 사용할 수 있도록 설계했습니다. 결과적으로 깊은 레이어를 통해 만들어진 정보압축을 통해서 anomaly detection에서 뛰어난 성능을 보여줬습니다.</p>

<p>아래의 글에서는 RVAE(Residual Variational Autoencoder)의 동기와 직면하였던 문제들에 대해서 설명드리고, anomaly detection 실험결과를 공유드리면서 글을 마치려고 합니다.</p>

<h2 id="related-works">
<a class="anchor" href="#related-works" aria-hidden="true"><span class="octicon octicon-link"></span></a>Related Works</h2>

<h3 id="residual-connection">
<a class="anchor" href="#residual-connection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Residual Connection</h3>

<p>딥러닝 모델이 깊어지게 되면, 모델의 표현능력이 커지게 되며 train loss는 더 작아져야합니다. 하지만, 모델이 깊어지게 되면서 <strong>train loss</strong>가 더 증가하기도 하며, 이를 degradation이라고 정의합니다. 아래의 이미지는 degradation 문제를 보여줍니다. [4]</p>

<p><img src="/blog/images/2020-06-05-Residual-Variational-Autoencoder/degradation.png" alt="degradation"></p>

<p>Resnet은 Residual connection을 통해서 Degradation 문제를 효과적으로 해결했습니다.[4]</p>

<p>Residual Connection은 직관적으로는 레이어간의 지름길을 뚫어주는 효과를 줍니다. Residual Connection의 구조는 아래의 그림을 통해서 확인할 수 있습니다.</p>

<p><img src="/blog/images/2020-06-05-Residual-Variational-Autoencoder/residual_learning.png" alt=""></p>

<h3 id="gradient-explosion-in-deep-network">
<a class="anchor" href="#gradient-explosion-in-deep-network" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gradient Explosion in deep network</h3>

<p>gradient explosion이란 학습과정에서 backpropagation 도중에 gradient가 갑작스럽게 증가하는 현상을 의미합니다.</p>

<p>딥러닝 연구에서 일반적으로 비선형적인 레이어를 효과적으로 쌓으면, 모델 성능이 좋아지는 것을 보여줍니다.
하지만, 레이어를 깊게 쌓을 때, graidnet vanishing/explosion 문제가 발생하여 오히려 모델 성능이 하락하는 문제가 발생됩니다. [4, 5, 6, 7, 10]</p>

<h3 id="anomaly-detection-based-on-autoencoder">
<a class="anchor" href="#anomaly-detection-based-on-autoencoder" aria-hidden="true"><span class="octicon octicon-link"></span></a>Anomaly detection based on Autoencoder</h3>

<p>anomaly detection에서 <strong>Autoencdoer</strong>구조는 많이 활용되고 있습니다.</p>

<p><img src="https://makinarocks.github.io/assets/images/20191215/1.png" alt="autoencoder"></p>

<p>Autoencoder는 x 라는 고차원의 데이터를 저차원의 latent space(z)로 압축하고 이를 다시 $\hat{x}$ 로 복원시키는 구조이며, 이때 MSE(Mean Squared Error) $\rVert x - \hat{x} \rVert^2$을 최소화하는 방향으로 학습이 진행됩니다. manifold 가설에 따르면, Autoencoder는 input data의 noise를 제거하면서 의미있는 정보압축을 진행하는 방향으로 학습되었다고 해석할 수 있습니다. [2]</p>

<p>이렇게 학습된 Autoencoder는 다음과 같은 과정을 통해서 anomayl detection을 수행합니다. [1]</p>

<ul>
  <li>입력 샘플을 인코더를 통해 저차원으로 압축합니다.</li>
  <li>압축된 샘플을 디코더를 통과시켜 다시 원래의 차원으로 복원합니다.</li>
  <li>입력 샘플과 복원 샘플의 복원 오차(reconstruction error)를 구합니다.</li>
  <li>복원 오차는 이상 점수(anomaly score)가 되어 threshold와 비교를 통해 이상 여부를 결정합니다.</li>
</ul>

<h2 id="anomaly-detection-based-on-variational-autoencoder">
<a class="anchor" href="#anomaly-detection-based-on-variational-autoencoder" aria-hidden="true"><span class="octicon octicon-link"></span></a>Anomaly detection based on Variational Autoencoder</h2>

<p>variational autoencoder는 저자 Kingma가 2014년에 Auto-Encoding Variational Bayes [4]을 통해서 소개한 바 있습니다. variational autoencoder는 해당 논문에서 소개한 reparameterization trick을 통해서 인코더가 생성하는 $m, \sigma$ 로 latent variable $z$를 샘플링하고 이로부터 posterior distribuion $p(x | z)$ 를 근사하여 학습하게 됩니다. [1]
</p>

<p><img src="https://makinarocks.github.io/assets/images/20191215/5.png" alt="vae"></p>

<ul>
  <li>$x \in R^n$: input data</li>
  <li>$z \in R^m$: latent variable</li>
  <li>$\hat{x} \in R^n$: reconstructed data</li>
</ul>

<p>variational autoencoder에서는 MSE(Mean Squared Error)에 KLD 항을 더하여 loss function이 정의됩니다.</p>

<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>s</mi><msub><mi>s</mi><mrow><mi>v</mi><mi>a</mi><mi>e</mi></mrow></msub><mo>=</mo><mo stretchy="false">∥</mo><mi>x</mi><mo>−</mo><mover accent="true"><mi>x</mi><mo>^</mo></mover><msup><mo stretchy="false">∥</mo><mn>2</mn></msup><mo>+</mo><mi>K</mi><mi>L</mi><mo stretchy="false">(</mo><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mi>m</mi><mo separator="true">,</mo><mi>σ</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>I</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">loss_{vae} = \rVert x - \hat{x} \rVert ^ 2 + KL( \mathcal{N} (m, \sigma), \mathcal{N}(0, I))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mclose">∥</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;">^</span></span></span></span></span></span><span class="mclose"><span class="mclose">∥</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mord mathdefault">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathcal" style="margin-right:0.14736em;">N</span></span><span class="mopen">(</span><span class="mord mathdefault">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14736em;">N</span></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span>

<p>결론적으로 VAE는 MSE(reconstruction error)를 최소화하는 과정에서 KLD도 감소시켜야합니다. reconstruction error와 KLD는 서로 반대방향으로 움직이는 경향이 있습니다. KLD이 0이 된다면 input data에 대해서 독립적인 latent variable을 생성하게 됩니다. 그렇게 되면, reconstruction error가 높아집니다. 반대로, reconstruction error가 0이 된다면, KLD의 값이 커지게 됩니다. 정리하면, KLD의 역할은 VAE 모델이 x와 z가 적당히 연관되면서 reconstruction과 상관없는 정보를 더 잘 버릴수 있도록 하는데 있습니다. [1]</p>

<p>이처럼 KLD는 훌륭하게 regularizer의 역할을 하며 오버피팅을 막아줍니다. 결과적으로 이것은 마치 주어진 상황에서 최적의 병목 구간 크기를 갖게 하는 효과를 갖습니다. KLD를 통해 VAE는 vanilla autoencoder에 비해 훨씬 나은 성능의 이상탐지(anomaly detection) 성능을 제공합니다. 실험을 통해 우리는 기존의 autoencoder는 너무 큰 bottleneck을 가지면 identity function이 되며 이상탐지 성능이 떨어지는 것에 반해, VAE는 bottleneck의 크기가 커질수록 이상탐지 성능이 오르는 효과를 갖는 것을 확인할 수 있었습니다. 따라서 AE 기반의 anomaly detection을 수행할 때, 기존에는 bottleneck의 크기를 hyper-parameter로 튜닝해야 했던 반면에, VAE의 경우에는 튜닝을 할 필요가 거의 없어졌습니다. [1]</p>

<h2 id="motivation">
<a class="anchor" href="#motivation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Motivation</h2>

<p>AE(autoencoder)와 VAE(variational AE)는 휼륭한 결과를 보여줬습니다. 하지만, 레이어를 깊게 쌓을 수 없다는 한계가 있었습니다. 실험을 통해서, 레이어의 수가 특정 임계치를 넘어가면 레이어의 수가 늘어날 수록 train loss가 증가하는 현상이 발생하는 것을 확인했습니다. 우리는 이것을 <strong>degradation</strong> 문제로 정의했습니다. [4]</p>

<p>이상적으로 AE의 최적의 레이어수가 있다하더라도, 레이어가 깊어지면 최적의 레이어수의 train loss와 같아야 합니다.</p>

<p><img src="/blog/images/2020-06-05-Residual-Variational-Autoencoder/degradation_ae.png" alt="Degradation"></p>

<p>위의 실험은 MNIST 데이터셋을 바탕으로 anomaly detection의 환경에서 진행하였습니다. n_layer당 실험세팅은 총 10개입니다. (0 을 제외하고 학습, 1을 제외하고 학습, …, 9를 제외하고 학습) 학습에서 제외된 클레스는 추후에 anomaly detection에서 anomaly가 됩니다. n_layers는 각 인코더, 디코더의 layer의 수를 의미합니다. 우리는 대칭적인 AE를 사용했으므로, 총 레이어의 수는 n_layers x 2 입니다.</p>

<p>위의 실험으로 더 깊은 레이어를 사용할 때, train loss가 더 증가하는 것을 확인할 수 있었습니다. 이는 레이어를 더 효과적으로 학습시킬 여지가 있음을 의미합니다. <strong>더 깊은 레이어</strong>의 AE 혹은 VAE 구조를 안정적으로 학습하기 위해서 Residual connection을 고려하게 되었습니다. [4]</p>

<h2 id="method">
<a class="anchor" href="#method" aria-hidden="true"><span class="octicon octicon-link"></span></a>Method</h2>

<p>본 섹션은 크게 3가지로 나누어서 설명드리겠습니다. 우리가 겪은 문제는 크게 3가지 입니다.</p>

<ol>
  <li>Degradation을 어떻게 해결할 것인가?</li>
  <li>AE 구조에서 residual connection을 어떻게 구현할 것인가?</li>
  <li>Residual AE에서 발생하는 gradient explosion은 어떻게 해결할 것인가?</li>
</ol>

<h3 id="degradation-residual-connection">
<a class="anchor" href="#degradation-residual-connection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Degradation: Residual Connection</h3>

<p>Degradation 문제를 해결하기 위해서 Residual Connection을 활용하였습니다.[4] 일반적으로 residual connection을 사용하게 되면, gradient의 지름길이 뚫려서 멀리까지 전달되는 효과가 있습니다. 이는 gradient vanishing 문제를 효과적으로 해결할 수 있습니다. 하지만, 내부적으로 이런 특징이 성능을 개선했다고 생각하지 않습니다. (gradient vanishing을 확인하지 못했습니다.) 또한, resnet 연구에서도 degradation의 원인이 gradient vanishing이 아니였다고 주장합니다.[4]</p>

<p>우리가 사용한 Residual connection 구조는 (a) original과 (b) identity입니다.[8]</p>

<p><img src="/blog/images/2020-06-05-Residual-Variational-Autoencoder/original-identity.png" alt="structure"></p>

<p>(b) proposed는 해당 identity 구조입니다. 위의 이미지에서 알 수 있듯이 단지 각 모듈의 순서의 변경만으로 성능차이가 나는 것을 확인할 수 있습니다. 하지만, 이론적으로 증명된 것이 아니고 AE 구조에서는 original과 identity 둘 중에 어떤 것이 더 좋은 성능을 보일지 알 수 없기 때문에 두 모델을 비교해봤습니다. 결과적으로 identity가 더 우수한 성능을 보여줬습니다. 자세한 내용은 Experiments에서 다루겠습니다.</p>

<p>아래는 우리가 만든 Residual AE의 구조입니다.</p>

<p><img src="/blog/images/2020-06-05-Residual-Variational-Autoencoder/residual_ae.jpeg" alt="직관적인 그림"></p>

<h3 id="gradient-explosion-gradient-clipping">
<a class="anchor" href="#gradient-explosion-gradient-clipping" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gradient Explosion: Gradient Clipping</h3>

<p>위의 과정을 거쳐서 residual AE/VAE가 완성되었지만, 해결해야 할 문제가 생겼습니다. 더 깊은 모델을 학습하는 과정에서 gradient explosion현상이 발생했습니다.[10] 이로 인해서 Residual Autoencoder를 학습할 때 아래와 같이 학습이 매우 불안정적으로 진행되었습니다. (g_norm은 gradient의 norm을 의미합니다.)</p>

<p><img src="/blog/images/2020-06-05-Residual-Variational-Autoencoder/gradient_explosion.png" alt="gradient explosion"></p>

<p>해당 그래프는 Residual AE를 MNIST데이터 셋을 학습시킨 결과입니다.</p>

<p>발생하는 원인에 대해서 loss surface가 아래와 같이 매우 극단적으로 나오는 것으로 추론할 수 있습니다.</p>

<p>이해를 돕기 위해서 아래와 같은 이미지로 설명드리겠습니다. 아래의 이미지는 모델의 파라미터가 $W \in R, b \in R$ 만 존재하는 경우의 loss surface입니다. 검은색 점은 모델의 파라미터에 대응하는 loss를 의미합니다. 학습이 진행되다가 loss surface가 매우 가파른 곳을 만나게되면, gradient의 값이 매우 커지게 됩니다. [7]</p>

<p><img src="/blog/images/2020-06-05-Residual-Variational-Autoencoder/ExplodingGradient_Razvan.png" alt="loss surface"></p>

<p>이를 해결하기 위해서 graidient를 clipping하여 사용했습니다. gradient clipping을 한다는 것은 weight가 학습되는 폭을 강제로 제한 하는 것입니다. 실제로 recurrent network를 학습시킬때 많이 활용하던 방법입니다. [12]</p>

<h2 id="experiments">
<a class="anchor" href="#experiments" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiments</h2>

<p>실험은 Residual AE/VAE 모델의 성능을 검증하기 위해서 설계되었습니다. 모델 성능은 train loss와 anomaly detection의 auroc를 통해서 검증하였습니다.</p>

<p>실험파트는 크게 두 가지 내용을 검증합니다. 첫 번째로 AE 구조에서 Residual Connection이 degradation 문제를 해결하였는지 검증하였습니다. 이러한 결과를 바탕으로 anomaly detection에서 긍정적인 방향으로 적용되는지 실험하였습니다.</p>

<h3 id="rae-vs-ae">
<a class="anchor" href="#rae-vs-ae" aria-hidden="true"><span class="octicon octicon-link"></span></a>RAE vs AE</h3>

<p>동일한 레이어의 대비 RAE와 AE 성능을 살펴보고, 각 모델의 최고 성능을 비교해보겠습니다.</p>

<h4 id="train-loss">
<a class="anchor" href="#train-loss" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train loss</h4>

<p><img src="/blog/images/2020-06-05-Residual-Variational-Autoencoder/lower_trainloss.png" alt=""></p>

<p>위의 그래프는 레이어의 수 당 평균 train loss를 나타냅니다. 해당 결과는 AE 구조에서 나타나던 degradation 문제를 경감시킨 것을 보여줍니다.</p>

<h4 id="auroc">
<a class="anchor" href="#auroc" aria-hidden="true"><span class="octicon octicon-link"></span></a>AUROC</h4>

<p><img src="/blog/images/2020-06-05-Residual-Variational-Autoencoder/auroc.png" alt=""></p>

<p>위의 그래프는 레이어 수 당 auroc를 나타냅니다. degradation 문제를 경감시키고 나서 anomaly detection에서의 성능을 확인해봤습니다. 아쉽게도 감소시킨 train loss가 직접적으로 auroc성능에 도움을 주지 못했습니다.</p>

<p>우리는 이것을 anomaly detection에서의 오버피팅이라고 생각하고 있습니다. 해석하자면, 모델이 정보를 압축 후 복원하는 것은 잘 하지만, 압축시킨 정보가 복원하는 것만 잘 하도록 학습이 되어 있는 것입니다.</p>

<h3 id="rvae-vs-vae">
<a class="anchor" href="#rvae-vs-vae" aria-hidden="true"><span class="octicon octicon-link"></span></a>RVAE vs VAE</h3>

<p>Variational AE, RAE 같은 경우에는 KLD 값의 영향으로 train loss를 비교하는 것은 어렵습니다. 따라서 AUROC 성능으로 검증하도록 하겠습4니다.</p>

<h4 id="auroc-1">
<a class="anchor" href="#auroc-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>AUROC</h4>

<p>아래의 실험은 SEED를 고정시키고 실험을 진행했습니다. 다른 논문의 VAE의 벤치마크 성능[13]과 비교해봤을 때, 큰 차이가 없는 것을 확인했습니다.</p>

<table>
  <thead>
    <tr>
      <th>novelty class</th>
      <th>RVAE-identity</th>
      <th>RVAE-original</th>
      <th>VAE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.99</td>
      <td>0.987</td>
      <td>0.98</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.408</td>
      <td>0.396</td>
      <td>0.38</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.99</td>
      <td>0.991</td>
      <td>0.99</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.969</td>
      <td>0.97</td>
      <td>0.967</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.944</td>
      <td>0.935</td>
      <td>0.929</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.968</td>
      <td>0.969</td>
      <td>0.96</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.962</td>
      <td>0.943</td>
      <td>0.956</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.909</td>
      <td>0.91</td>
      <td>0.90</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.974</td>
      <td>0.972</td>
      <td>0.973</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.848</td>
      <td>0.833</td>
      <td>0.81</td>
    </tr>
  </tbody>
</table>

<p>위의 실험결과를 통해서 RVAE 모델이 VAE모델보다 AUROC 성능을 향상 시킨 것을 확인했습니다. 실험결과를 보면 이렇게 해석할 수 있습니다. Residual Connection의 영향으로 모델의 표현능력을 증가시켰습니다. KLD를 활용한 regularization과 합쳐지면서 모델은 더 효과적인 압축을 진행할 수 있게 됩니다.</p>

<h2 id="summary">
<a class="anchor" href="#summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary</h2>

<p>더 깊은 레이어를 쌓으면서 발생했던 degradation 문제와 이를 해결하기 위한 residual connection에 대해서 다뤄습니다. 또한, AE 구조에 residual connection을 적용하기 위한 노력들과 깊은 fully connected layer와 batch normalization을 같이 사용하면서 발생한 gradient explosion 현상을 해결하기 위해서 gradient clipping을 적용하였습니다.</p>

<p>결과적으로 RAE를 통해서 깊은 레이어의 모델에서 발생하는 degradation문제를 해결할 수 있었고, 여기에 KLD regularization을 적용하여 AUROC(anomaly detection 성능)을 높였습니다.</p>

<h2 id="references">
<a class="anchor" href="#references" aria-hidden="true"><span class="octicon octicon-link"></span></a>References</h2>

<p>[1] <a href="https://makinarocks.github.io/Autoencoder-based-anomaly-detection/">Makinarocks: Autoencoder based Anomaly Detection</a></p>

<p>[2] Stanislav Pidhorskyi et al., Generative Probabilistic Novelty Detection with Adversarial Autoencoders, NeurIPS, 2018</p>

<p>[3] Kingma et al., Auto-Encoding Variational Bayes, ICLR, 2014</p>

<p>[4] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning
for image recognition. In CVPR, 2016</p>

<p>[5] Y. Bengio, P. Simard, and P. Frasconi. Learning long-term dependencies with gradient descent is difficult. IEEE Transactions on Neural
Networks, 5(2):157–166, 1994.</p>

<p>[6] S. Hochreiter. Untersuchungen zu dynamischen neuronalen netzen.
Diploma thesis, TU Munich, 1991.</p>

<p>[7] X. Glorot and Y. Bengio. Understanding the difficulty of training
deep feedforward neural networks. In AISTATS, 2010</p>

<p>[8] K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in
deep residual networks. In ECCV, 2016</p>

<p>[9] https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/</p>

<p>[10] Song Mei, Andrea Montanari, and Phan-Minh Nguyen. A mean field view of the landscape
of two-layer neural networks. Proceedings of the National Academy of Sciences, 115(33):
E7665–E7671, 2018.</p>

<p>[11] A. Veit, M. Wilber, and S. Belongie. Residual networks
behave like ensembles of relatively shallow network. In
NIPS, 2016.</p>

<p>[12] Pascanu, R., Mikolov, T., and Bengio, Y. (2013b). On the difficulty of training recurrent neural
networks. In Proceedings of the 30th International Conference on Machine Learning (ICML
2013).</p>

<p>[13] Kim, K., Shim, S., Lim, Y., Jeon, J., Choi, J., Kim, B., Yoon, A., 2020. Rapp: Novelty
Detection With Reconstruction Along Projection Pathway. ICLR 2020</p>


  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="RoundTable/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/deeplearning/anomayl%20detection/2020/06/05/Residual-Variational-Autoencoder.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
